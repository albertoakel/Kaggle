{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad81fc6-9b46-4f35-925d-2db4951eb091",
   "metadata": {},
   "source": [
    "# *Resultados*\n",
    "* * nan -> median\n",
    "* categoric(onehotcode)+Number\n",
    "* R¬≤: 0.9150 |0.9093(log)\n",
    "* ‚è±Ô∏è Tempo de execu√ß√£o: 4.43 segundos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4acd10-4071-4c54-accc-faec2204f47c",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d810cf0-cb72-4333-bff6-cdb929b7c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# üè† House Prices - Pipelines\n",
    "# =====================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, \n",
    "                       message='Found unknown categories in columns')\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Scikit-learn - Model selection e avalia√ß√£o\n",
    "#from sklearn.model_selection import train_test_split, cross_val_score, KFold, RandomizedSearchCV\n",
    "\n",
    "# Scikit-learn - Pr√©-processamento e pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Scikit-learn - Modelos lineares\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV\n",
    "\n",
    "# Scikit-learn - Ensemble methods\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Scikit-learn - M√©tricas de avalia√ß√£o\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Distribui√ß√µes para busca de hiperpar√¢metros\n",
    "from scipy.stats import randint, uniform,loguniform\n",
    "\n",
    "from setup_notebook import setup_path\n",
    "setup_path()\n",
    "from src.model_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a59ed39-5049-4c92-bfce-d03925bcf4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# üìÅ 1. Leitura dos dados\n",
    "# =====================================================\n",
    "dfo = pd.read_csv(\"/home/akel/PycharmProjects/Kaggle/HousePrices/data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a62d97-392e-4159-9233-c98a8203f770",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a55432-25f1-4618-a0c8-eeb43e3feaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=dfo.copy()\n",
    "# =====================================================\n",
    "# üßπ 2. Pr√©-processamento inicial\n",
    "# =====================================================\n",
    "# remo√ß√£o de colunas com muitos nulos (> 10%)\n",
    "colnull_train=df_train.columns[(df_train.isnull().sum()/df_train.shape[0]>0.1)] # \n",
    "df_train=df_train.drop(columns=colnull_train,axis=1)\n",
    "\n",
    "id_train=df_train['Id']\n",
    "\n",
    "# obtendo nome das vari√°veis categ√≥ricas e num√©ricas\n",
    "num_features = df_train.select_dtypes(include=['number']).columns.drop(['Id', 'SalePrice'])\n",
    "cat_features = df_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# =====================================================\n",
    "# üß© 3. Pr√©-processadores\n",
    "# =====================================================\n",
    "# NAN -> median\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# categoric -> binario onehotcode \n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first',\n",
    "                             sparse_output=False,\n",
    "                             handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessador = ColumnTransformer(transformers=[\n",
    "    ('cat', cat_transformer, cat_features),\n",
    "    ('num', num_transformer, num_features)   \n",
    "],verbose_feature_names_out=False) \n",
    "\n",
    "\n",
    "# =====================================================\n",
    "#  ü§ñ 4.Modelos\n",
    "# =====================================================\n",
    "\n",
    "model_lr=LinearRegression()\n",
    "model_LR=Pipeline([ ('preprocess', preprocessador), \n",
    "                        ('model', model_lr )])\n",
    "\n",
    "model_rf1 = RandomForestRegressor(random_state=42)\n",
    "model_RF1 = Pipeline([ ('preprocess', preprocessador), \n",
    "                        ('model',model_rf1 )])\n",
    "\n",
    "model_rf2=RandomForestRegressor(bootstrap=True, max_depth=25, max_features=0.3,\n",
    "                      min_samples_split=2,  min_samples_leaf= 1,n_estimators=100, n_jobs=-1,\n",
    "                      random_state=42)\n",
    "model_RF2 = Pipeline([ ('preprocess', preprocessador), \n",
    "                        ('model',model_rf2 )])\n",
    "\n",
    "model_xg1 = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "model_XGB1 = Pipeline([ ('preprocess', preprocessador), \n",
    "                        ('model', model_xg1 )])\n",
    "\n",
    "model_xg2 = XGBRegressor( objective='reg:squarederror', n_estimators=700,\n",
    "                         subsample= 0.6,reg_lambda= 0.5,reg_alpha= 1.0,\n",
    "                         max_depth= 3,learning_rate= 0.073,\n",
    "                         colsample_bytree= 0.7,random_state=42,\n",
    "                         n_jobs=-1 ) \n",
    "model_XGB2 = Pipeline([ ('preprocess', preprocessador), \n",
    "                        ('model',model_xg2 )])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9687aa-ff57-4ba8-acd6-ad4a87d2cc8d",
   "metadata": {},
   "source": [
    "## 3. Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d0fb657-4673-45ec-a9a5-1363e1c8ce60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: ü§ñ LR\n",
      "MAE: 0.095\n",
      "RMSE: 0.1826\n",
      "R¬≤: 0.8035\n",
      "Modelo: ü§ñ RF1\n",
      "MAE: 0.0934\n",
      "RMSE: 0.1384\n",
      "R¬≤: 0.8871\n",
      "Modelo: ü§ñ RF2\n",
      "MAE: 0.0905\n",
      "RMSE: 0.1375\n",
      "R¬≤: 0.8886\n",
      "Modelo: ü§ñ XGB1\n",
      "MAE: 0.0976\n",
      "RMSE: 0.145\n",
      "R¬≤: 0.876\n",
      "Modelo: ü§ñ XGB2\n",
      "MAE: 0.0865\n",
      "RMSE: 0.1255\n",
      "R¬≤: 0.9071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9071005180824829"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df_train.drop(['Id', 'SalePrice'], axis=1)\n",
    "y=np.log1p(df_train['SalePrice'])\n",
    "#y=df_train['SalePrice']\n",
    "start_time = time.time()\n",
    "r2=run_model(X,y,model_LR,'LR')\n",
    "\n",
    "r2=run_model(X,y,model_RF1,'RF1')\n",
    "\n",
    "r2=run_model(X,y,model_RF2,'RF2')\n",
    "\n",
    "run_model(X,y,model_XGB1,'XGB1')  \n",
    "run_model(X,y,model_XGB2,'XGB2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a348594-2d5f-4221-9c90-8d80d3b82c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #===========================================================\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# param_dist_rf = {\n",
    "#     'n_estimators': np.arange(100, 800, 100),  # n√∫mero de √°rvores\n",
    "#     'max_depth': [None, 5, 10, 15, 20, 25],      # profundidade m√°xima\n",
    "#     'min_samples_split': [2, 5, 10, 15],         # m√≠nimo de amostras para dividir um n√≥\n",
    "#     'min_samples_leaf': [1, 2, 4, 6],            # m√≠nimo de amostras por folha\n",
    "#     'max_features': [0.3, 0.5, 0.7, 0.8, 1.0, 'sqrt',None],       # n¬∫ de features usadas em cada split\n",
    "#     'bootstrap': [True]                   # amostragem com ou sem reposi√ß√£o\n",
    "# }\n",
    "# rf=RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "# rand_rf = RandomizedSearchCV(\n",
    "#     estimator=rf,\n",
    "#     param_distributions=param_dist_rf,\n",
    "#     n_iter=50,                   \n",
    "#     cv=cv,\n",
    "#     scoring='r2',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2,\n",
    "# error_score='raise')\n",
    "\n",
    "# model_RSearch_rf = Pipeline([ ('preprocess', preprocessador), \n",
    "#                         ('model',rand_rf )])\n",
    "\n",
    "# param_dist_xg = {\n",
    "#     'n_estimators': np.arange(200, 1000, 100),\n",
    "#     'learning_rate': np.linspace(0.01, 0.2, 10),\n",
    "#     'max_depth': np.arange(3, 8),\n",
    "#     'subsample': np.linspace(0.6, 1.0, 5),\n",
    "#     'colsample_bytree': np.linspace(0.6, 1.0, 5),\n",
    "#     'reg_alpha': np.linspace(0, 1, 5),\n",
    "#     'reg_lambda': np.linspace(0.5, 2, 5)}\n",
    "\n",
    "# xb_s = XGBRegressor(\n",
    "#         objective='reg:squarederror',\n",
    "#         eval_metric='rmse',\n",
    "#         random_state=42,\n",
    "#         tree_method='hist',  # acelera em CPU\n",
    "#         n_jobs=-1)\n",
    "\n",
    "# rand_xgb = RandomizedSearchCV(\n",
    "#     estimator=xb_s,\n",
    "#     param_distributions=param_dist_xg,\n",
    "#     n_iter=50,  # n√∫mero de combina√ß√µes testadas\n",
    "#     cv=cv,\n",
    "#     scoring='r2',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# model_RSearch_xgb = Pipeline([ ('preprocess', preprocessador), \n",
    "#                          ('model',rand_xgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8c2afae-77c2-472c-b83f-6e3aaa119cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=df_train.drop(['Id', 'SalePrice'], axis=1)\n",
    "# y=np.log1p(df_train['SalePrice'])\n",
    "# start_time = time.time()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# model_RSearch_rf.fit(X_train,y_train)\n",
    "# end_time = time.time()\n",
    "# print(f\"‚è±Ô∏è Tempo de execu√ß√£o: {end_time - start_time:.2f} segundos\")\n",
    "# rand_rf.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
