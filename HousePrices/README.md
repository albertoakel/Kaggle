# ğŸ  House Prices â€” PrevisÃ£o de ImÃ³veis Residenciais

Projeto baseado no desafio **[House Prices â€“ Advanced Regression Techniques (Kaggle)]**.
O objetivo Ã© prever o **preÃ§o final de casas em Ames, Iowa**, utilizando tÃ©cnicas modernas de **Machine Learning para dados tabulares**.


---

## ğŸ“Œ Objetivo do Projeto

Desenvolver um pipeline completo de **prÃ©-processamento, modelagem e avaliaÃ§Ã£o**, comparando modelos lineares regularizados e mÃ©todos ensemble, com foco em:

* Desempenho preditivo
* Controle de overfitting
* Reprodutibilidade

---

## ğŸ” O que vocÃª vai encontrar neste projeto

* **EDA detalhada** com anÃ¡lise estatÃ­stica e visual
*  **PrÃ©-processamento robusto** (imputaÃ§Ã£o, normalizaÃ§Ã£o, one-hot encoding)
* **Modelos avaliados**:

  * **[Modelos Lineares](https://github.com/albertoakel/Kaggle/blob/master/HousePrices/notebook/models_Linear.ipynb)**
  * **[Random Forest-Ensemble](https://github.com/albertoakel/Kaggle/blob/master/HousePrices/notebook/models_Random_Forest.ipynb)**
  * **[XGBoosting](https://github.com/albertoakel/Kaggle/blob/master/HousePrices/notebook/models_XGBoost.ipynb)**
* **AvaliaÃ§Ã£o comparativa** com MAE, RMSE e RÂ²
*  **Artefatos persistidos** (preprocessador e melhor modelo)

### Principais Highlights do Projeto

* **PrÃ©-processamento padronizado e reutilizÃ¡vel:** utilizaÃ§Ã£o do `preprocessador_v0.joblib`, garantindo consistÃªncia no tratamento dos dados em todos os experimentos, reprodutibilidade dos resultados e prevenÃ§Ã£o de *data leakage*.

* **TransformaÃ§Ã£o robusta das variÃ¡veis:**

  * variÃ¡veis numÃ©ricas tratadas com imputaÃ§Ã£o por mediana e padronizaÃ§Ã£o;
  * variÃ¡veis categÃ³ricas convertidas via *One-Hot Encoding*;
  * todo o fluxo encapsulado em um Ãºnico `ColumnTransformer`, assegurando coerÃªncia entre treino, validaÃ§Ã£o e inferÃªncia.

* **Pipelines integrados por modelo:** cada algoritmo Ã© treinado dentro de um pipeline Ãºnico, integrando automaticamente o prÃ©-processamento e a etapa de regressÃ£o, reduzindo erros experimentais e facilitando comparaÃ§Ãµes justas.

* **AvaliaÃ§Ã£o sistemÃ¡tica via validaÃ§Ã£o cruzada (K-Fold):** anÃ¡lise do desempenho mÃ©dio (RÂ²) e da variabilidade entre *folds*, permitindo avaliar nÃ£o apenas acurÃ¡cia, mas tambÃ©m **estabilidade e capacidade de generalizaÃ§Ã£o**.

* **ComparaÃ§Ã£o entre mÃºltiplas famÃ­lias de modelos:**

  * **Modelos Lineares**: Linear Regression, Ridge e Lasso (configuraÃ§Ãµes padrÃ£o e ajustadas), usados como baseline interpretÃ¡vel e referÃªncia de estabilidade;
  * **Random Forest**: versÃµes padrÃ£o e ajustadas, explorando nÃ£o linearidades e interaÃ§Ãµes entre variÃ¡veis;
  * **XGBoost**: trÃªs configuraÃ§Ãµes progressivamente regularizadas, focadas em maximizar desempenho e controle de *overfitting*.

* **AvaliaÃ§Ã£o padronizada e reutilizÃ¡vel:** uso das funÃ§Ãµes auxiliares `metricas_model()` e `valida()` para uniformizar o cÃ¡lculo de MAE, RMSE e RÂ², simplificando a comparaÃ§Ã£o objetiva entre diferentes estratÃ©gias de modelagem.

* **EvoluÃ§Ã£o clara de complexidade e desempenho:** a progressÃ£o dos modelos evidencia ganhos consistentes ao sair de abordagens lineares para ensembles baseados em Ã¡rvores e, finalmente, para *boosting* regularizado, culminando no melhor compromisso entre **erro, estabilidade e generalizaÃ§Ã£o** com o XGBoost ajustado

---

## ğŸ“Š Resultados dos Modelos

AvaliaÃ§Ã£o realizada sobre o conjunto de teste (target transformado com `log1p`).

| Modelo                   | MAE        | RMSE       | RÂ²         |status|
| ------------------------ | ---------- | ---------- | ---------- |-|
| Linear Regression        | 0.0950     | 0.1826     | 0.8035     |
| Ridge (config 0)         | 0.0945     | 0.1679     | 0.8337     |
| Ridge (config 1)         | 0.0963     | 0.1346     | 0.8932     |ğŸ¥‰
| LASSO (config 0)         | 0.1089     | 0.1508     | 0.8660     |
| LASSO (config 1)         | 0.0994     | 0.1384     | 0.8871     |
| Random Forest (config 0) | 0.0934     | 0.1382     | 0.8874     |
| Random Forest (config 1) | 0.0919     | 0.1383     | 0.8872     |
| XGBoost (config 0)       | 0.0976     | 0.1450     | 0.8760     |
| XGBoost (config 1)       | 0.0894     | 0.1320     | 0.8973     |ğŸ¥ˆ
| **XGBoost (config 2)**   | **0.0838** | **0.1240** | **0.9093** |ğŸ†

ğŸ“Œ Nota: A pontuaÃ§Ã£o final submetida ao Kaggle foi **0.13202** (14/11/2025).

---

## ğŸ“ Estrutura do Projeto

O projeto segue uma arquitetura modular, separando engenharia de dados, prÃ©-processamento e modelagem. O preprocessamento Ã© encapsulado em um artefato versionado (joblib) e aplicado via pipelines do scikit-learn, garantindo reprodutibilidade, prevenÃ§Ã£o de data leakage e comparaÃ§Ã£o justa entre modelos.

```
HousePrices/
â”‚
â”œâ”€â”€ app/                     # AplicaÃ§Ãµes futuras (deploy)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Dados originais
â”‚   â””â”€â”€ processed/           # Bases pÃ³s-processadas
â”‚
â”œâ”€â”€ image/                   # Imagens e figuras
â”‚
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ eda_HP.ipynb
â”‚   â”œâ”€â”€ models_Linear.ipynb
â”‚   â”œâ”€â”€ models_Random_Forest.ipynb
â”‚   â”œâ”€â”€ models_XGBoost.ipynb
â”‚   â”œâ”€â”€ XGB2_submission.ipynb
â”‚   â””â”€â”€ setup_notebook.py
â”‚
â”œâ”€â”€ sandbox/                 # Testes, rascunhos e experimentos
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess_utils.py
â”‚   â”œâ”€â”€ model_utils.py
â”‚   â”œâ”€â”€ functions.py
â”‚   â”œâ”€â”€ preprocess_house_prices_v1.joblib
â”‚   â””â”€â”€ melhor_modelo.h5
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
### Fluxograma de operaÃ§Ã£o
```mermaid
---
config:
  theme: base
  layout: dagre
  look: neo
---
flowchart TB
 subgraph s1["âš™ï¸ Preparacao"]
        B1["Split treino/teste<br>(ANTES de decisÃµes estatÃ­sticas)"]
        B2["IdentificaÃ§Ã£o de colunas<br>com muitos nulos"]
        B3@{ label: "RemoÃ§Ã£o de colunas<br>'&gt;10% nulos'<br>(base treino)" }
        B4["DefiniÃ§Ã£o de features"]
        B4a["NumÃ©ricas"]
        B4b["CategÃ³ricas"]
        B5["CriaÃ§Ã£o do preprocessador<br>(ColumnTransformer)"]
        B6["ğŸ“¦ Artefato joblib<br>preprocess_house_prices_v1.joblib"]
  end
 subgraph Persistencia["ğŸ’¾ PersistÃªncia de Dados"]
        C["data/processed/"]
        C1["X_train_final.csv"]
        C2["X_test_final.csv"]
        C3["y_train_final.csv"]
        C4["y_test_final.csv"]
  end
 subgraph Treinamento[" "]
        D["ğŸ““ models_[nome_do_modelo].ipynb"]
        D1["Carrega CSVs + Preprocessador"]
        D2["Cria Pipeline<br>(preprocess + modelo)"]
        E["fit()"]
        E1["preprocess.fit_transform(X_train)"]
        F["Modelo ([--]/LR)"]
        G["ValidaÃ§Ã£o Cruzada<br>(K-Fold no Treino)"]
        H["AvaliaÃ§Ã£o Final<br>(MÃ©tricas no Teste)"]
  end
    A["data/raw/train.csv"] --> B["preprocess_utils.py"]
    B L_B_B1_0@-.-> B1
    B1 --> B2
    B2 --> B3
    B3 --> B4 & C
    B4 --> B4a & B4b & B5
    B5 --> B6
    C --> C1 & C2 & C3 & C4 & D
    B6 -.-> D
    D --> D1
    D1 --> D2
    D2 --> E
    E --> E1
    E1 --> F
    F --> G & H
    H --> I["ğŸ“ˆ GrÃ¡ficos & AnÃ¡lise"]

    B3@{ shape: diam}
    classDef fase_prep fill:##f0f0f0,stroke:#f05252,color:#000
    classDef fase_data fill:##f0f0f0,stroke:#0ea5e9,color:#000
    classDef fase_model fill:##f0f0f0,stroke:#22c55e,color:#000
    linkStyle 1 stroke:#000000,fill:none

    L_B_B1_0@{ curve: natural }
```


---

## ğŸš€ Como executar o projeto

### 1ï¸âƒ£ Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Executar notebooks

```bash
jupyter notebook
```

### 3ï¸âƒ£ PrÃ©-processamento automatizado

```bash
python src/preprocess_utils_tic.py
```

