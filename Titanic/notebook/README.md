# üìì Notebooks ‚Äî Titanic (GUIA)

Esta pasta re√∫ne os **notebooks principais do projeto Titanic**, organizados por etapa de an√°lise, modelagem e submiss√£o. Cada notebook √© relativamente independente, por√©m todos compartilham um **pr√©-processamento padronizado**, garantindo consist√™ncia, rastreabilidade e reprodutibilidade dos resultados ao longo do projeto.

---

## üóÇ Estrutura dos Notebooks

### üîç An√°lise Explorat√≥ria de Dados (EDA)

* **EDA.ipynb**
  An√°lise explorat√≥ria completa do dataset Titanic, incluindo avalia√ß√£o de qualidade dos dados, distribui√ß√µes univariadas, an√°lises bivariadas, dispers√£o, correla√ß√£o e identifica√ß√£o de padr√µes associados √† vari√°vel resposta **Survived**.
  Este notebook fundamenta diretamente as decis√µes de **pr√©-processamento e engenharia de atributos** utilizadas nos modelos preditivos.

---

### üå≤ Modelos Ensemble ‚Äî Random Forest

* **models_randomForest.ipynb**
  Avalia√ß√£o de modelos baseados em √°rvores do tipo Random Forest:

  * Random Forest (baseline)
  * Random Forest com hiperpar√¢metros ajustados

  √änfase na captura de n√£o linearidades, intera√ß√µes entre vari√°veis e an√°lise de robustez.

* **Hiperparameter_search_RF.ipynb**
  Busca sistem√°tica de hiperpar√¢metros para Random Forest, com valida√ß√£o cruzada e an√°lise comparativa de desempenho.

* **RF_Submission.ipynb**
  Gera√ß√£o do arquivo de submiss√£o Kaggle utilizando o melhor modelo Random Forest selecionado.

---

### üöÄ Gradient Boosting ‚Äî XGBoost

* **models_XGBoost.ipynb**
  Avalia√ß√£o de modelos XGBoost em diferentes n√≠veis de complexidade:

  * XGBoost (baseline)
  * XGBoost com ajustes intermedi√°rios
  * XGBoost otimizado

  Foco em desempenho preditivo e controle de overfitting.

* **Hiperparameter_search_XGB.ipynb**
  Busca de hiperpar√¢metros do XGBoost, explorando regulariza√ß√£o, profundidade e taxa de aprendizado.

* **XGB_Submission.ipynb**
  Notebook dedicado √† gera√ß√£o da submiss√£o Kaggle com o melhor modelo XGBoost.

---

### üß† Gradient Boosting ‚Äî CatBoost

* **models_CBTBoost.ipynb**
  Modelagem utilizando CatBoost, explorando seu tratamento nativo de vari√°veis categ√≥ricas e estabilidade em datasets tabulares.

* **Hiperparameter_search_CBT.ipynb**
  Otimiza√ß√£o de hiperpar√¢metros do CatBoost com valida√ß√£o cruzada.

* **CBT_Submission.ipynb**
  Gera√ß√£o do arquivo de submiss√£o baseado no melhor modelo CatBoost.

---

## ‚öôÔ∏è Padr√µes adotados

* Pr√©-processamento centralizado e reutiliz√°vel (via objetos serializados)
* Pipelines integrados (pr√©-processamento + modelo)
* Avalia√ß√£o com m√©tricas adequadas √† classifica√ß√£o bin√°ria (ex.: Accuracy, ROC-AUC, F1-score)
* Valida√ß√£o cruzada para an√°lise de estabilidade e generaliza√ß√£o

---

## ‚úÖ Modelos finais e compara√ß√µes

Os modelos **Random Forest**, **XGBoost** e **CatBoost** s√£o comparados de forma consistente sob o mesmo pipeline de dados. A escolha do modelo final considera:

* Desempenho m√©dio em valida√ß√£o cruzada
* Estabilidade entre folds
* Capacidade de generaliza√ß√£o

‚û°Ô∏è O modelo recomendado √© aquele que apresenta o melhor compromisso entre desempenho e robustez, conforme os resultados obtidos nos notebooks de busca e valida√ß√£o.

--