
# ğŸš¢ Titanic â€” AnÃ¡lise de SobrevivÃªncia de Passageiros

Projeto baseado no desafio **[Titanic: Machine Learning from Disaster (Kaggle)]**.
O objetivo Ã© prever **a sobrevivÃªncia dos passageiros do Titanic** a partir de caracterÃ­sticas demogrÃ¡ficas, socioeconÃ´micas e de viagem, utilizando tÃ©cnicas clÃ¡ssicas e modernas de **Machine Learning para classificaÃ§Ã£o supervisionada**.


## ğŸ“Œ Objetivo do Projeto

Desenvolver um pipeline completo de **anÃ¡lise exploratÃ³ria, prÃ©-processamento, modelagem e avaliaÃ§Ã£o**, com foco em:

* interpretaÃ§Ã£o dos dados
* engenharia de atributos
* comparaÃ§Ã£o de modelos de classificaÃ§Ã£o
* controle de overfitting

---

## ğŸ” O que vocÃª vai encontrar neste projeto

* **EDA detalhada** com anÃ¡lise estatÃ­stica e visual dos fatores de sobrevivÃªncia
* **Tratamento de dados ausentes** (`Age`, `Cabin`, `Embarked`)
* **Feature engineering** (tamanho da famÃ­lia, tÃ­tulo do nome, variÃ¡veis binÃ¡rias)
* **PrÃ©-processamento completo**:

  * imputaÃ§Ã£o
  * normalizaÃ§Ã£o
  * codificaÃ§Ã£o categÃ³rica
* **Modelos avaliados**:

  * Random Forest Classifier
  * Gradient Boosting / XGBoost
* **AvaliaÃ§Ã£o comparativa** com mÃ©tricas de classificaÃ§Ã£o
* **Modelo final pronto para submissÃ£o no Kaggle**

---

## ğŸ“Š Resultados dos Modelos

| Modelo                            | CV ROC-AUC (Â±Ïƒ) | Test ROC-AUC | Test ACC (0.5) | Test ACC (Opt) | Status |
|-----------------------------------| --------------- | ------ |----------------| --------- | ------ |
| Random Forest (Base)              | 0.8600 Â± 0.0501 | 0.8710 | 0.8060         | 0.8134    |        |
| **Random Forest (Random Search)** | **0.8531 Â± 0.0643** | **0.8905** | **0.8246**       | **0.8358** | ğŸ†     |
| Random Forest (Refine)            | 0.8760 Â± 0.0516 | 0.8688 | 0.8060         | 0.8284    | ğŸ¥ˆ     |
| Random Forest (Bayes)             | 0.8750 Â± 0.0554 | 0.8752 | 0.8022         | 0.8172    |        |
| XGBoost (Base)                    | 0.8235 Â± 0.0485 | 0.8520 | 0.7836         | 0.8022    |        |
| XGBoost (Random Search)           | 0.8411 Â± 0.0558 | 0.8738 | 0.8172         | 0.8209    |        |
| XGBoost (Refine)                  | 0.8491 Â± 0.0494 | 0.8749 | 0.8321         | 0.8358    | ğŸ¥ˆ     |
| XGBoost (Bayes)                   | 0.8475 Â± 0.0408 | 0.8695 | 0.8134         | 0.8209    |        |
| CatBoost (Base)                   | 0.8523 Â± 0.0529 | 0.8811 | 0.8172         | 0.8284    | ğŸ¥‰     |
| CatBoost (Random Search)          | 0.8460 Â± 0.0508 | 0.8730 | 0.8134         | 0.8134    |        |
| CatBoost (Refine)                 | 0.8460 Â± 0.0466 | 0.8739 | 0.8246         | 0.8246    |        |
| CatBoost (Bayes)                  | 0.8539 Â± 0.0535 | 0.8678 | 0.8246         | 0.8284    |        |

ğŸ“Œ Nota: A pontuaÃ§Ã£o final submetida ao Kaggle foi **0.79425** (14/11/2025). 

---

## ğŸ§  Principais Aprendizados



---

## ğŸ“ Estrutura do Projeto

```
Titanic/
â”‚
â”œâ”€â”€ app/                     # AplicaÃ§Ãµes futuras (deploy)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Dados originais do Kaggle
â”‚   â””â”€â”€ processed/           # Bases tratadas
â”‚
â”œâ”€â”€ image/                   # GrÃ¡ficos e figuras
â”‚
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ eda_titanic.ipynb
â”‚   â”œâ”€â”€ models_baseline.ipynb
â”‚   â”œâ”€â”€ models_ensemble.ipynb
â”‚   â””â”€â”€ submission.ipynb
â”‚
â”œâ”€â”€ sandbox/                 # Experimentos e testes
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess_utils.py
â”‚   â”œâ”€â”€ feature_utils.py
â”‚   â”œâ”€â”€ model_utils.py
â”‚   â””â”€â”€ best_model.joblib
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Como executar o projeto

### 1ï¸âƒ£ Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Executar notebooks

```bash
jupyter notebook
```

### 3ï¸âƒ£ PrÃ©-processamento automatizado

```bash
python src/preprocess_utils_tic.py
```

---

## ğŸ“Œ ObservaÃ§Ãµes Finais

Este projeto foi desenvolvido como um **estudo clÃ¡ssico de classificaÃ§Ã£o supervisionada**, com foco em **interpretaÃ§Ã£o, boas prÃ¡ticas e clareza metodolÃ³gica**, servindo como:

* introduÃ§Ã£o sÃ³lida ao Machine Learning
* benchmark tÃ©cnico
